import cv2
import numpy as np

global col2, col4, col6, col8
col2 = ()
col4 = ()
col6 = ()
col8 = ()

colors = [
    [(222, 192, 95), (255, 195, 85), (43, 100, 173), (236, 154, 190)],
    [(42, 95, 50), (81, 34, 109), (83, 57, 154), (69, 116, 154)],
    [(255, 0, 0), (0, 255, 0), (0, 0, 255), (81, 34, 109)]
]

def color_generator():
    selec = np.random.choice(len(colors))
    return colors[selec]

col2, col4, col6, col8 = color_generator()

global steps
steps = [
    {'step': 8, 'color': col2, 'range': (153, 204)},
    {'step': 6, 'color': col4, 'range': (102, 153)},
    {'step': 4, 'color': col6, 'range': (51, 102)},
    {'step': 2, 'color': col8, 'range': (0, 51)}
]

def check_steps():
    global steps
    steps = [
        {'step': 8, 'color': col2, 'range': (153, 204)},
        {'step': 6, 'color': col4, 'range': (102, 153)},
        {'step': 4, 'color': col6, 'range': (51, 102)},
        {'step': 2, 'color': col8, 'range': (0, 51)}
    ]



# Load the pre-trained model and config files
net = cv2.dnn.readNetFromCaffe('deploy.prototxt', 'mobilenet_iter_73000.caffemodel')

cap = cv2.VideoCapture(1)

while True:
    ret, frame = cap.read()
    if not ret:
        break

    height, width, channels = frame.shape
    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)
    net.setInput(blob)
    detections = net.forward()

    final_canvas = np.ones((height, width, 3), dtype=np.uint8) * 255

    # Use a flag to check whether a valid human detection has occurred in the current frame
    valid_detection = False

    if detections is not None:
        if col2 == (): #If col2 is empty
            col2, col4, col6, col8 = color_generator()  # For each frame, use a different set of colors
            check_steps()
        for f in range(detections.shape[2]):
            confidence = detections[0, 0, f, 2]

            if confidence > 0.6:
                box = detections[0, 0, f, 3:7] * np.array([width, height, width, height])
                (startX, startY, endX, endY) = box.astype("int")

                if startX < endX and startY < endY:  # This checks if the bounding box is valid.
                    face_neck = frame[startY:endY, startX:endX]

                    if face_neck.size > 0:  # This checks if the sliced face_neck is not empty.
                        bw_face_neck = cv2.cvtColor(face_neck, cv2.COLOR_BGR2GRAY)
                        valid_detection = True  # Set the flag to True as we have a valid detection

                        height, width = bw_face_neck.shape
                        white_canvas = np.ones((height, width, 3), dtype=np.uint8) * 255

                        # Drawing lines based on pixel color conditions
                        for s in steps:
                            step = s['step']
                            color = s['color']
                            lower, upper = s['range']
                            
                            # Create a mask where the conditions are met
                            mask = (bw_face_neck[::step, ::step] >= lower) & (bw_face_neck[::step, ::step] < upper)
                            
                            # Get the indices where mask is True and adjust the coordinates
                            y, x = np.where(mask)
                            y = y * step
                            x = x * step
                            
                            # Draw lines on the white_canvas
                            for i, j in zip(x, y):
                                cv2.line(white_canvas, (i - step//2, j - step//2), (i + step//2, j + step//2), color, 1)

                        # After processing all steps, assign white_canvas to the appropriate location on final_canvas
                        if white_canvas.shape == final_canvas[startY:endY, startX:endX].shape:
                            final_canvas[startY:endY, startX:endX] = white_canvas
                        else:
                            cv2.imshow('frame', frame)
                            col2 = ()
                            col4 = ()
                            col6 = ()
                            col8 = ()
                            print(f"Shape mismatch: white_canvas: {white_canvas.shape}, final_canvas slice: {final_canvas[startY:endY, startX:endX].shape}")
                    else:
                        cv2.imshow('frame', frame)
                        col2 = ()
                        col4 = ()
                        col6 = ()
                        col8 = ()

        if valid_detection:
            cv2.imshow('frame', final_canvas)
        else:
            cv2.imshow('frame', frame)  # If no valid detection, display the original frame
            col2 = ()
            col4 = ()
            col6 = ()
            col8 = ()

    key = cv2.waitKey(1)
    if key == ord('q') or key == 27:
        break

cap.release()
cv2.destroyAllWindows()
